import os
import json
import uuid
from datetime import datetime
from typing import Dict, List, Optional
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from flask_socketio import SocketIO, emit
from pydantic import BaseModel, Field
from dataclasses import dataclass
import threading
import time
import urllib.parse

app = Flask(__name__)
app.config['SECRET_KEY'] = 'benchboard-secret-key'
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*")

# æ•°æ®å­˜å‚¨
@dataclass
class TeamData:
    team_id: str
    team_name: str
    last_update: datetime
    stats: Dict
    is_active: bool = True
    best_qps: float = 0.0
    best_qps_time: Optional[datetime] = None
    best_latency: float = float('inf')
    best_latency_time: Optional[datetime] = None

# å…¨å±€å­˜å‚¨
teams_data: Dict[str, TeamData] = {}
data_lock = threading.Lock()

# Pydanticæ¨¡å‹å®šä¹‰
class OperationStat(BaseModel):
    operations: int = Field(..., description="æ“ä½œæ•°é‡")
    errors: int = Field(..., description="é”™è¯¯æ•°é‡")

class OperationsStats(BaseModel):
    sensorData: OperationStat
    sensorRW: OperationStat
    batchRW: OperationStat
    query: OperationStat

class HighPriorityStats(BaseModel):
    sensorDataCount: int = Field(..., description="ä¼ æ„Ÿå™¨æ•°æ®ä¸ŠæŠ¥é«˜ä¼˜å…ˆçº§è¯·æ±‚æ•°")
    sensorRWCount: int = Field(..., description="ä¼ æ„Ÿå™¨è¯»å†™æ“ä½œé«˜ä¼˜å…ˆçº§è¯·æ±‚æ•°")
    batchRWCount: int = Field(..., description="æ‰¹é‡æ“ä½œé«˜ä¼˜å…ˆçº§è¯·æ±‚æ•°")
    queryCount: int = Field(..., description="æŸ¥è¯¢æ“ä½œé«˜ä¼˜å…ˆçº§è¯·æ±‚æ•°")
    totalCount: int = Field(..., description="é«˜ä¼˜å…ˆçº§è¯·æ±‚æ€»æ•°")
    percentage: float = Field(..., description="é«˜ä¼˜å…ˆçº§è¯·æ±‚å æ¯”ï¼ˆ%ï¼‰")

class PerformanceMetrics(BaseModel):
    avgSentQPS: float = Field(..., description="å¹³å‡å‘é€ QPS")
    avgCompletedQPS: float = Field(..., description="å¹³å‡å®Œæˆ QPS")
    errorRate: float = Field(..., description="é”™è¯¯ç‡ï¼ˆ%ï¼‰")

class LatencyDistribution(BaseModel):
    avg: float = Field(..., description="å¹³å‡å»¶è¿Ÿï¼ˆmsï¼‰")
    min: float = Field(..., description="æœ€å°å»¶è¿Ÿï¼ˆmsï¼‰")
    max: float = Field(..., description="æœ€å¤§å»¶è¿Ÿï¼ˆmsï¼‰")
    buckets: List[int] = Field(..., description="å»¶è¿Ÿåˆ†å¸ƒæ¡¶è®¡æ•°")
    highPriorityCount: Optional[int] = Field(None, description="é«˜ä¼˜å…ˆçº§è¯·æ±‚æ•°é‡")
    highPriorityAvg: Optional[float] = Field(None, description="é«˜ä¼˜å…ˆçº§å¹³å‡å»¶è¿Ÿï¼ˆmsï¼‰")
    highPriorityMin: Optional[float] = Field(None, description="é«˜ä¼˜å…ˆçº§æœ€å°å»¶è¿Ÿï¼ˆmsï¼‰")
    highPriorityMax: Optional[float] = Field(None, description="é«˜ä¼˜å…ˆçº§æœ€å¤§å»¶è¿Ÿï¼ˆmsï¼‰")
    highPriorityBuckets: Optional[List[int]] = Field(None, description="é«˜ä¼˜å…ˆçº§å»¶è¿Ÿåˆ†å¸ƒæ¡¶è®¡æ•°")

class LatencyAnalysis(BaseModel):
    sensorData: LatencyDistribution
    sensorRW: LatencyDistribution
    batchRW: LatencyDistribution
    query: LatencyDistribution

class StatsReport(BaseModel):
    totalElapsed: float = Field(..., description="æ€»è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰")
    totalSent: int = Field(..., description="å‘é€è¯·æ±‚æ•°")
    totalOps: int = Field(..., description="å®Œæˆè¯·æ±‚æ•°")
    totalErrors: int = Field(..., description="æ€»é”™è¯¯æ•°")
    totalSaveDelayErrors: int = Field(..., description="æ€»å› ä¸ºå‘ç°è½ç›˜æ—¶é—´è¶…æ—¶è€Œäº§ç”Ÿçš„é”™è¯¯æ•°")
    pending: int = Field(..., description="å¾…å¤„ç†è¯·æ±‚æ•°")
    operations: OperationsStats
    highPriorityStats: HighPriorityStats
    performanceMetrics: PerformanceMetrics
    latencyAnalysis: LatencyAnalysis

def calculate_p99_latency(buckets: List[int]) -> float:
    """è®¡ç®—P99å»¶è¿Ÿ"""
    bucket_boundaries = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, float('inf')]
    total_requests = sum(buckets)
    if total_requests == 0:
        return 0.0
    
    p99_threshold = total_requests * 0.99
    cumulative = 0
    
    for i, count in enumerate(buckets):
        cumulative += count
        if cumulative >= p99_threshold:
            if i == 0:
                return bucket_boundaries[i]
            else:
                # çº¿æ€§æ’å€¼
                prev_cumulative = cumulative - count
                ratio = (p99_threshold - prev_cumulative) / count
                lower_bound = bucket_boundaries[i-1] if i > 0 else 0
                upper_bound = bucket_boundaries[i]
                return lower_bound + ratio * (upper_bound - lower_bound)
    
    return bucket_boundaries[-2]  # è¿”å›æœ€åä¸€ä¸ªæœ‰é™è¾¹ç•Œ

def calculate_data_loss_rate(stats: Dict) -> float:
    """è®¡ç®—æ•°æ®ä¸¢å¤±ç‡"""
    total_sent = stats.get('totalSent', 0)
    total_ops = stats.get('totalOps', 0)
    pending = stats.get('pending', 0)
    
    if total_sent == 0:
        return 0.0
    
    # æ•°æ®ä¸¢å¤± = å‘é€æ•° - å®Œæˆæ•° - å¾…å¤„ç†æ•°
    lost = total_sent - total_ops - pending
    return (lost / total_sent) * 100 if lost > 0 else 0.0

def calculate_overall_metrics(stats: Dict) -> Dict:
    """è®¡ç®—æ•´ä½“æ€§èƒ½æŒ‡æ ‡"""
    latency_analysis = stats.get('latencyAnalysis', {})
    
    # è®¡ç®—æ€»ä½“å¹³å‡å»¶è¿Ÿ
    total_latency = 0
    total_requests = 0
    
    for operation_type in ['sensorData', 'sensorRW', 'batchRW', 'query']:
        if operation_type in latency_analysis:
            op_data = latency_analysis[operation_type]
            op_requests = sum(op_data.get('buckets', []))
            if op_requests > 0:
                total_latency += op_data.get('avg', 0) * op_requests
                total_requests += op_requests
    
    avg_latency = total_latency / total_requests if total_requests > 0 else 0
    
    # è®¡ç®—æ€»ä½“P99å»¶è¿Ÿï¼ˆä½¿ç”¨sensorDataä½œä¸ºä¸»è¦æŒ‡æ ‡ï¼‰
    sensor_buckets = latency_analysis.get('sensorData', {}).get('buckets', [])
    p99_latency = calculate_p99_latency(sensor_buckets)
    
    # è®¡ç®—é«˜ä¼˜å…ˆçº§å¹³å‡å»¶è¿Ÿ
    high_priority_latency = 0
    high_priority_count = 0
    
    for operation_type in ['sensorData', 'sensorRW', 'batchRW', 'query']:
        if operation_type in latency_analysis:
            op_data = latency_analysis[operation_type]
            if op_data.get('highPriorityAvg') and op_data.get('highPriorityCount'):
                high_priority_latency += op_data['highPriorityAvg'] * op_data['highPriorityCount']
                high_priority_count += op_data['highPriorityCount']
    
    avg_high_priority_latency = high_priority_latency / high_priority_count if high_priority_count > 0 else 0
    
    return {
        'avg_latency': avg_latency,
        'p99_latency': p99_latency,
        'high_priority_latency': avg_high_priority_latency,
        'data_loss_rate': calculate_data_loss_rate(stats)
    }

def save_team_data(team_id: str, team_name: str, stats: Dict):
    """ä¿å­˜å›¢é˜Ÿæ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶"""
    data_dir = "data"
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    
    filename = f"{data_dir}/{team_id}.json"
    data = {
        "team_id": team_id,
        "team_name": team_name,
        "timestamp": datetime.now().isoformat(),
        "stats": stats
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_team_data(team_id: str) -> Optional[Dict]:
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å›¢é˜Ÿæ•°æ®"""
    filename = f"data/{team_id}.json"
    if os.path.exists(filename):
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

@app.route('/')
def dashboard():
    """Webçœ‹æ¿é¡µé¢"""
    return render_template('dashboard.html')

@app.route('/api/stats/report', methods=['POST'])
def submit_stats():
    """æ¥æ”¶å‹æµ‹ç»“æœä¸ŠæŠ¥"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "No data provided"}), 400
        
        # éªŒè¯æ•°æ®æ ¼å¼
        stats_report = StatsReport(**data)
        
        # è·å–å›¢é˜Ÿä¿¡æ¯
        team_id = request.headers.get('X-Team-ID')
        encoded_team_name = request.headers.get('X-Team-Name', f'Team-{team_id}')
        
        # è§£ç URLç¼–ç çš„å›¢é˜Ÿåç§°
        try:
            team_name = urllib.parse.unquote(encoded_team_name)
        except:
            team_name = encoded_team_name  # å¦‚æœè§£ç å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å€¼
        
        if not team_id:
            return jsonify({"error": "X-Team-ID header is required"}), 400
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        current_qps = data.get('performanceMetrics', {}).get('avgCompletedQPS', 0)
        current_metrics = calculate_overall_metrics(data)
        current_latency = current_metrics['avg_latency']
        
        # ä¿å­˜æ•°æ®
        with data_lock:
            if team_id in teams_data:
                team_data = teams_data[team_id]
                # æ›´æ–°æœ€ä½³QPSè®°å½•
                if current_qps > team_data.best_qps:
                    team_data.best_qps = current_qps
                    team_data.best_qps_time = datetime.now()
                
                # æ›´æ–°æœ€ä½³å»¶è¿Ÿè®°å½•
                if current_latency > 0 and current_latency < team_data.best_latency:
                    team_data.best_latency = current_latency
                    team_data.best_latency_time = datetime.now()
                
                # æ›´æ–°å…¶ä»–ä¿¡æ¯
                team_data.team_name = team_name
                team_data.last_update = datetime.now()
                team_data.stats = data
                team_data.is_active = True
            else:
                teams_data[team_id] = TeamData(
                    team_id=team_id,
                    team_name=team_name,
                    last_update=datetime.now(),
                    stats=data,
                    best_qps=current_qps,
                    best_qps_time=datetime.now() if current_qps > 0 else None,
                    best_latency=current_latency if current_latency > 0 else float('inf'),
                    best_latency_time=datetime.now() if current_latency > 0 else None
                )
        
        # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
        save_team_data(team_id, team_name, data)
        
        # é€šè¿‡WebSocketå¹¿æ’­æ›´æ–°
        socketio.emit('stats_update', {
            'team_id': team_id,
            'team_name': team_name,
            'stats': data,
            'timestamp': datetime.now().isoformat(),
            'metrics': current_metrics,
            'best_qps': teams_data[team_id].best_qps,
            'best_qps_time': teams_data[team_id].best_qps_time.isoformat() if teams_data[team_id].best_qps_time else None,
            'best_latency': teams_data[team_id].best_latency if teams_data[team_id].best_latency != float('inf') else None,
            'best_latency_time': teams_data[team_id].best_latency_time.isoformat() if teams_data[team_id].best_latency_time else None
        })
        
        return jsonify({"message": "Stats submitted successfully", "team_id": team_id}), 200
        
    except Exception as e:
        return jsonify({"error": str(e)}), 400

@app.route('/api/teams', methods=['GET'])
def get_teams():
    """è·å–æ‰€æœ‰å›¢é˜Ÿæ•°æ®"""
    with data_lock:
        teams_list = []
        for team_id, team_data in teams_data.items():
            teams_list.append({
                'team_id': team_id,
                'team_name': team_data.team_name,
                'last_update': team_data.last_update.isoformat(),
                'is_active': team_data.is_active
            })
        return jsonify(teams_list)

@app.route('/api/teams/<team_id>', methods=['GET'])
def get_team_stats(team_id):
    """è·å–ç‰¹å®šå›¢é˜Ÿçš„ç»Ÿè®¡æ•°æ®"""
    with data_lock:
        if team_id in teams_data:
            team_data = teams_data[team_id]
            metrics = calculate_overall_metrics(team_data.stats)
            return jsonify({
                'team_id': team_id,
                'team_name': team_data.team_name,
                'last_update': team_data.last_update.isoformat(),
                'stats': team_data.stats,
                'metrics': metrics,
                'best_qps': team_data.best_qps,
                'best_qps_time': team_data.best_qps_time.isoformat() if team_data.best_qps_time else None,
                'best_latency': team_data.best_latency if team_data.best_latency != float('inf') else None,
                'best_latency_time': team_data.best_latency_time.isoformat() if team_data.best_latency_time else None
            })
        else:
            return jsonify({"error": "Team not found"}), 404

@app.route('/api/teams/<team_id>/history', methods=['GET'])
def get_team_history(team_id):
    """è·å–å›¢é˜Ÿå†å²æ•°æ®"""
    data = load_team_data(team_id)
    if data:
        return jsonify(data)
    else:
        return jsonify({"error": "Team history not found"}), 404

@socketio.on('connect')
def handle_connect():
    """å®¢æˆ·ç«¯è¿æ¥æ—¶å‘é€å½“å‰æ•°æ®"""
    with data_lock:
        for team_id, team_data in teams_data.items():
            metrics = calculate_overall_metrics(team_data.stats)
            emit('stats_update', {
                'team_id': team_id,
                'team_name': team_data.team_name,
                'stats': team_data.stats,
                'timestamp': team_data.last_update.isoformat(),
                'metrics': metrics,
                'best_qps': team_data.best_qps,
                'best_qps_time': team_data.best_qps_time.isoformat() if team_data.best_qps_time else None,
                'best_latency': team_data.best_latency if team_data.best_latency != float('inf') else None,
                'best_latency_time': team_data.best_latency_time.isoformat() if team_data.best_latency_time else None
            })

def cleanup_inactive_teams():
    """æ¸…ç†ä¸æ´»è·ƒçš„å›¢é˜Ÿï¼ˆè¶…è¿‡5åˆ†é’Ÿæ²¡æœ‰æ›´æ–°ï¼‰"""
    while True:
        time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        current_time = datetime.now()
        with data_lock:
            inactive_teams = []
            for team_id, team_data in teams_data.items():
                if (current_time - team_data.last_update).total_seconds() > 300:  # 5åˆ†é’Ÿ
                    team_data.is_active = False
                    inactive_teams.append(team_id)
            
            # ç§»é™¤ä¸æ´»è·ƒçš„å›¢é˜Ÿ
            for team_id in inactive_teams:
                del teams_data[team_id]

if __name__ == '__main__':
    # å¯åŠ¨æ¸…ç†çº¿ç¨‹
    cleanup_thread = threading.Thread(target=cleanup_inactive_teams, daemon=True)
    cleanup_thread.start()
    
    print("ğŸš€ Starting BenchBoard server on port 8080...")
    
    # å¯åŠ¨æœåŠ¡å™¨
    socketio.run(app, host='0.0.0.0', port=8080, debug=True) 