#!/usr/bin/env python3
"""
å®æ—¶æ¼”ç¤ºæµ‹è¯•è„šæœ¬
æ¨¡æ‹Ÿå¤šä¸ªå›¢é˜ŸæŒç»­ä¸ŠæŠ¥æ•°æ®ï¼Œç”¨äºæµ‹è¯•å®æ—¶æ›´æ–°åŠŸèƒ½

ä½¿ç”¨æ–¹æ³•:
python3 test_realtime_demo.py [--duration 60] [--interval 5]

åŠŸèƒ½:
- 3ä¸ªå›¢é˜ŸæŒç»­ä¸ŠæŠ¥æ•°æ®
- æ¨¡æ‹Ÿä¸åŒçš„æ€§èƒ½è¡¨ç°
- å¯é…ç½®è¿è¡Œæ—¶é•¿å’Œä¸ŠæŠ¥é—´éš”
- å®æ—¶æ˜¾ç¤ºä¸ŠæŠ¥çŠ¶æ€
"""

import requests
import json
import time
import urllib.parse
import argparse
import threading
import random
from datetime import datetime
from typing import Dict

# æœåŠ¡å™¨é…ç½®
SERVER_URL = "http://localhost:8080"

# å›¢é˜Ÿé…ç½®
TEAMS = [
    {
        "id": "team1",
        "name": "æ€§èƒ½æµ‹è¯•ç»„",
        "base_qps": 12.0,
        "base_latency": 35.0,
        "performance_trend": "improving"  # improving, declining, stable
    },
    {
        "id": "team2", 
        "name": "å‹åŠ›æµ‹è¯•ç»„",
        "base_qps": 8.5,
        "base_latency": 55.0,
        "performance_trend": "stable"
    },
    {
        "id": "team3",
        "name": "ç¨³å®šæ€§æµ‹è¯•ç»„", 
        "base_qps": 15.2,
        "base_latency": 28.0,
        "performance_trend": "declining"
    }
]

class RealtimeDemo:
    """å®æ—¶æ¼”ç¤ºç±»"""
    
    def __init__(self, duration: int = 60, interval: int = 5):
        self.duration = duration
        self.interval = interval
        self.running = True
        self.submission_count = 0
        self.success_count = 0
        self.error_count = 0
        self.start_time = datetime.now()
        
    def generate_dynamic_data(self, team: Dict, round_num: int) -> Dict:
        """æ ¹æ®å›¢é˜Ÿé…ç½®å’Œè½®æ¬¡ç”ŸæˆåŠ¨æ€æ•°æ®"""
        
        # åŸºç¡€æ€§èƒ½æŒ‡æ ‡
        base_qps = team["base_qps"]
        base_latency = team["base_latency"]
        
        # æ ¹æ®æ€§èƒ½è¶‹åŠ¿è°ƒæ•´æ•°æ®
        trend = team["performance_trend"]
        if trend == "improving":
            qps_multiplier = 1.0 + (round_num * 0.05)  # QPSé€æ¸æå‡
            latency_multiplier = 1.0 - (round_num * 0.02)  # å»¶è¿Ÿé€æ¸é™ä½
        elif trend == "declining":
            qps_multiplier = 1.0 - (round_num * 0.03)  # QPSé€æ¸ä¸‹é™
            latency_multiplier = 1.0 + (round_num * 0.04)  # å»¶è¿Ÿé€æ¸å¢åŠ 
        else:  # stable
            qps_multiplier = 1.0 + random.uniform(-0.1, 0.1)  # å°å¹…æ³¢åŠ¨
            latency_multiplier = 1.0 + random.uniform(-0.05, 0.05)
        
        # æ·»åŠ éšæœºæ³¢åŠ¨
        qps_variation = random.uniform(0.8, 1.2)
        latency_variation = random.uniform(0.9, 1.1)
        
        current_qps = base_qps * qps_multiplier * qps_variation
        current_latency = base_latency * latency_multiplier * latency_variation
        
        # ç¡®ä¿æ•°å€¼åœ¨åˆç†èŒƒå›´å†…
        current_qps = max(1.0, min(50.0, current_qps))
        current_latency = max(10.0, min(200.0, current_latency))
        
        # æ ¹æ®æ€§èƒ½è®¡ç®—å…¶ä»–æŒ‡æ ‡
        error_rate = max(0.1, 8.0 - current_qps * 0.3)  # QPSè¶Šé«˜é”™è¯¯ç‡è¶Šä½
        total_requests = int(current_qps * 120)  # å‡è®¾è¿è¡Œ2åˆ†é’Ÿ
        error_count = int(total_requests * error_rate / 100)
        
        return {
            "totalElapsed": 120.0 + random.uniform(-10, 10),
            "totalSent": total_requests + random.randint(-50, 50),
            "totalOps": total_requests - error_count,
            "totalErrors": error_count,
            "totalSaveDelayErrors": random.randint(0, 5),
            "totalAvgLatency": current_latency,
            "highPriorityAvgDelayLatency": current_latency * 0.7,
            "totalVerifyErrorRate": max(0.1, 5.0 - current_qps * 0.15),
            "pending": random.randint(5, 25),
            "operations": {
                "sensorData": {
                    "operations": int(total_requests * 0.5),
                    "errors": int(error_count * 0.6)
                },
                "sensorRW": {
                    "operations": int(total_requests * 0.25),
                    "errors": int(error_count * 0.2)
                },
                "batchRW": {
                    "operations": int(total_requests * 0.15),
                    "errors": int(error_count * 0.15)
                },
                "query": {
                    "operations": int(total_requests * 0.1),
                    "errors": int(error_count * 0.05)
                }
            },
            "highPriorityStats": {
                "sensorDataCount": random.randint(40, 80),
                "sensorRWCount": random.randint(15, 35),
                "batchRWCount": random.randint(10, 25),
                "queryCount": random.randint(8, 20),
                "totalCount": random.randint(80, 150),
                "percentage": random.uniform(8.0, 15.0)
            },
            "performanceMetrics": {
                "avgSentQPS": current_qps + random.uniform(-0.5, 0.5),
                "avgCompletedQPS": current_qps,
                "errorRate": error_rate
            },
            "latencyAnalysis": {
                "sensorData": {
                    "avg": current_latency,
                    "min": current_latency * 0.3,
                    "max": current_latency * 4,
                    "buckets": self.generate_latency_buckets(current_latency),
                    "highPriorityCount": random.randint(40, 70),
                    "highPriorityAvg": current_latency * 0.7,
                    "highPriorityMin": current_latency * 0.2,
                    "highPriorityMax": current_latency * 2.5,
                    "highPriorityBuckets": self.generate_latency_buckets(current_latency * 0.7, True)
                },
                "sensorRW": {
                    "avg": current_latency + 15,
                    "min": current_latency * 0.4,
                    "max": current_latency * 3.5,
                    "buckets": self.generate_latency_buckets(current_latency + 15)
                },
                "batchRW": {
                    "avg": current_latency + 40,
                    "min": current_latency * 0.8,
                    "max": current_latency * 6,
                    "buckets": self.generate_latency_buckets(current_latency + 40)
                },
                "query": {
                    "avg": current_latency - 8,
                    "min": current_latency * 0.25,
                    "max": current_latency * 2.8,
                    "buckets": self.generate_latency_buckets(current_latency - 8)
                }
            }
        }
    
    def generate_latency_buckets(self, avg_latency: float, is_high_priority: bool = False) -> list:
        """æ ¹æ®å¹³å‡å»¶è¿Ÿç”Ÿæˆå»¶è¿Ÿåˆ†å¸ƒæ¡¶"""
        # ç®€åŒ–çš„å»¶è¿Ÿåˆ†å¸ƒç”Ÿæˆ
        base_total = 500 if not is_high_priority else 50
        
        # æ ¹æ®å¹³å‡å»¶è¿Ÿå†³å®šåˆ†å¸ƒ
        if avg_latency < 30:
            # ä½å»¶è¿Ÿåˆ†å¸ƒï¼Œå¤§éƒ¨åˆ†åœ¨å‰å‡ ä¸ªæ¡¶
            return [
                int(base_total * 0.4), int(base_total * 0.3), int(base_total * 0.15),
                int(base_total * 0.08), int(base_total * 0.04), int(base_total * 0.02),
                int(base_total * 0.01), 0, 0, 0, 0, 0
            ]
        elif avg_latency < 60:
            # ä¸­ç­‰å»¶è¿Ÿåˆ†å¸ƒ
            return [
                int(base_total * 0.2), int(base_total * 0.25), int(base_total * 0.2),
                int(base_total * 0.15), int(base_total * 0.1), int(base_total * 0.06),
                int(base_total * 0.03), int(base_total * 0.01), 0, 0, 0, 0
            ]
        else:
            # é«˜å»¶è¿Ÿåˆ†å¸ƒï¼Œæ›´åˆ†æ•£
            return [
                int(base_total * 0.1), int(base_total * 0.15), int(base_total * 0.18),
                int(base_total * 0.15), int(base_total * 0.12), int(base_total * 0.1),
                int(base_total * 0.08), int(base_total * 0.06), int(base_total * 0.04),
                int(base_total * 0.02), 0, 0
            ]
    
    def submit_team_data(self, team: Dict, round_num: int) -> bool:
        """æäº¤å›¢é˜Ÿæ•°æ®"""
        try:
            url = f"{SERVER_URL}/api/stats/report"
            headers = {
                'Content-Type': 'application/json; charset=utf-8',
                'Accept-Charset': 'utf-8',
                'X-Team-ID': team["id"],
                'X-Team-Name': urllib.parse.quote(team["name"])
            }
            
            data = self.generate_dynamic_data(team, round_num)
            response = requests.post(
                url,
                headers=headers,
                data=json.dumps(data, ensure_ascii=False).encode('utf-8'),
                timeout=10
            )
            
            if response.status_code == 200:
                self.success_count += 1
                return True
            else:
                self.error_count += 1
                return False
                
        except Exception:
            self.error_count += 1
            return False
    
    def print_status(self, round_num: int):
        """æ‰“å°å½“å‰çŠ¶æ€"""
        elapsed = (datetime.now() - self.start_time).total_seconds()
        remaining = max(0, self.duration - elapsed)
        
        print(f"\rğŸ”„ ç¬¬{round_num}è½® | "
              f"â±ï¸ {elapsed:.0f}s/{self.duration}s | "
              f"ğŸ“Š æˆåŠŸ:{self.success_count} å¤±è´¥:{self.error_count} | "
              f"â³ å‰©ä½™:{remaining:.0f}s", end="", flush=True)
    
    def run_team_simulation(self, team: Dict):
        """è¿è¡Œå•ä¸ªå›¢é˜Ÿçš„æ¨¡æ‹Ÿ"""
        round_num = 0
        
        while self.running:
            round_num += 1
            success = self.submit_team_data(team, round_num)
            self.submission_count += 1
            
            # æ‰“å°çŠ¶æ€ï¼ˆåªæœ‰ç¬¬ä¸€ä¸ªå›¢é˜Ÿæ‰“å°ï¼Œé¿å…é‡å¤ï¼‰
            if team["id"] == "team1":
                self.print_status(round_num)
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            elapsed = (datetime.now() - self.start_time).total_seconds()
            if elapsed >= self.duration:
                self.running = False
                break
            
            # ç­‰å¾…ä¸‹æ¬¡æäº¤
            time.sleep(self.interval)
    
    def run(self):
        """è¿è¡Œæ¼”ç¤º"""
        print(f"ğŸš€ å¯åŠ¨å®æ—¶æ¼”ç¤º")
        print(f"ğŸ“Š é…ç½®: æŒç»­æ—¶é—´={self.duration}ç§’, ä¸ŠæŠ¥é—´éš”={self.interval}ç§’")
        print(f"ğŸ‘¥ å›¢é˜Ÿ: {len(TEAMS)}ä¸ª")
        print("="*60)
        
        # å¯åŠ¨å¤šçº¿ç¨‹æ¨¡æ‹Ÿ
        threads = []
        for team in TEAMS:
            thread = threading.Thread(target=self.run_team_simulation, args=(team,))
            thread.start()
            threads.append(thread)
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # æ‰“å°æœ€ç»ˆç»“æœ
        print(f"\n\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"   - æ€»æäº¤æ¬¡æ•°: {self.submission_count}")
        print(f"   - æˆåŠŸæ¬¡æ•°: {self.success_count}")
        print(f"   - å¤±è´¥æ¬¡æ•°: {self.error_count}")
        print(f"   - æˆåŠŸç‡: {(self.success_count/self.submission_count*100):.1f}%")
        print(f"   - å®é™…è¿è¡Œæ—¶é—´: {(datetime.now() - self.start_time).total_seconds():.1f}ç§’")
        
        print(f"\nğŸ’¡ ç°åœ¨å¯ä»¥:")
        print(f"   1. è®¿é—® {SERVER_URL} æŸ¥çœ‹å®æ—¶çœ‹æ¿")
        print(f"   2. ç‚¹å‡»å›¢é˜Ÿå¡ç‰‡æŸ¥çœ‹å†å²æ•°æ®")
        print(f"   3. è§‚å¯Ÿä¸åŒå›¢é˜Ÿçš„æ€§èƒ½è¶‹åŠ¿")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="BenchBoardå®æ—¶æ¼”ç¤ºæµ‹è¯•")
    parser.add_argument("--duration", type=int, default=60, help="è¿è¡ŒæŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’")
    parser.add_argument("--interval", type=int, default=5, help="ä¸ŠæŠ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5ç§’")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æœåŠ¡å™¨è¿æ¥
    try:
        response = requests.get(f"{SERVER_URL}/", timeout=5)
        if response.status_code != 200:
            print(f"âŒ æœåŠ¡å™¨è¿æ¥å¤±è´¥: {SERVER_URL}")
            print("è¯·ç¡®ä¿è¿è¡Œ: python3 app.py")
            return 1
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥æœåŠ¡å™¨: {e}")
        print("è¯·ç¡®ä¿è¿è¡Œ: python3 app.py")
        return 1
    
    # è¿è¡Œæ¼”ç¤º
    demo = RealtimeDemo(duration=args.duration, interval=args.interval)
    demo.run()
    
    return 0

if __name__ == "__main__":
    exit(main()) 